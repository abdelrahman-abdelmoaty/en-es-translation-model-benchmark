{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":692482,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":525061,"modelId":539100}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n#Legacy TensorFlow BackEnd\nos.environ['TF_USE_LEGACY_KERAS'] = '1'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:58:39.060416Z","iopub.execute_input":"2025-12-19T16:58:39.061121Z","iopub.status.idle":"2025-12-19T16:58:39.069142Z","shell.execute_reply.started":"2025-12-19T16:58:39.061087Z","shell.execute_reply":"2025-12-19T16:58:39.068300Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport pathlib\nimport tensorflow_text as tf_text\nimport pickle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:00:05.327786Z","iopub.execute_input":"2025-12-19T17:00:05.328087Z","iopub.status.idle":"2025-12-19T17:00:05.332212Z","shell.execute_reply.started":"2025-12-19T17:00:05.328065Z","shell.execute_reply":"2025-12-19T17:00:05.331399Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy()\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:58:57.255282Z","iopub.execute_input":"2025-12-19T16:58:57.256032Z","iopub.status.idle":"2025-12-19T16:58:58.249894Z","shell.execute_reply.started":"2025-12-19T16:58:57.256011Z","shell.execute_reply":"2025-12-19T16:58:58.249085Z"}},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\nNumber of devices: 2\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1766163538.204091      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1766163538.204693      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"config = {\n    \"learning_rate\": 1e-4,\n    \"batch_size\": 256,\n    \"epochs\": 20,\n    \"max_vocab_size\":5000,\n    \"max_length\":50\n}\n\nGLOBAL_BATCH = config['batch_size'] * strategy.num_replicas_in_sync\nLEARNING_RATE = config['learning_rate']\nEPOCHS = config['epochs']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:58:58.250554Z","iopub.execute_input":"2025-12-19T16:58:58.250819Z","iopub.status.idle":"2025-12-19T16:58:58.255063Z","shell.execute_reply.started":"2025-12-19T16:58:58.250796Z","shell.execute_reply":"2025-12-19T16:58:58.254397Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"path_to_zip = tf.keras.utils.get_file(\n    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n    extract=True)\n\npath_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:59:05.481551Z","iopub.execute_input":"2025-12-19T16:59:05.482143Z","iopub.status.idle":"2025-12-19T16:59:05.605830Z","shell.execute_reply.started":"2025-12-19T16:59:05.482113Z","shell.execute_reply":"2025-12-19T16:59:05.605083Z"}},"outputs":[{"name":"stdout","text":"Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n2638744/2638744 [==============================] - 0s 0us/step\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def load_data(path):\n  text = path.read_text(encoding='utf-8')\n\n  lines = text.splitlines()\n  pairs = [line.split('\\t') for line in lines]\n\n  context = np.array([context for target, context in pairs])\n  target = np.array([target for target, context in pairs])\n\n  return target, context","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:59:05.882485Z","iopub.execute_input":"2025-12-19T16:59:05.882730Z","iopub.status.idle":"2025-12-19T16:59:05.887274Z","shell.execute_reply.started":"2025-12-19T16:59:05.882704Z","shell.execute_reply":"2025-12-19T16:59:05.886681Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"context_raw,target_raw = load_data(path_to_file)\nprint(context_raw[-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:59:08.055240Z","iopub.execute_input":"2025-12-19T16:59:08.055921Z","iopub.status.idle":"2025-12-19T16:59:08.622749Z","shell.execute_reply.started":"2025-12-19T16:59:08.055890Z","shell.execute_reply":"2025-12-19T16:59:08.621915Z"}},"outputs":[{"name":"stdout","text":"If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(target_raw[-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:59:08.624092Z","iopub.execute_input":"2025-12-19T16:59:08.624407Z","iopub.status.idle":"2025-12-19T16:59:08.628715Z","shell.execute_reply.started":"2025-12-19T16:59:08.624388Z","shell.execute_reply":"2025-12-19T16:59:08.627850Z"}},"outputs":[{"name":"stdout","text":"Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"split_idx = int(0.9 * len(target_raw))\n\nX_train = context_raw[:split_idx]\ny_train = target_raw[:split_idx]\n\nX_val = context_raw[split_idx:]\ny_val = target_raw[split_idx:]\n\nBUFFER_SIZE = len(X_train)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n\n# Validation dataset (no shuffle needed)\nval_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\nval_dataset = val_dataset.batch(GLOBAL_BATCH, drop_remainder=True).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:59:17.484670Z","iopub.execute_input":"2025-12-19T16:59:17.485353Z","iopub.status.idle":"2025-12-19T16:59:17.817723Z","shell.execute_reply.started":"2025-12-19T16:59:17.485328Z","shell.execute_reply":"2025-12-19T16:59:17.817163Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"idx = np.random.randint(0,63)\ncontext,target = next(iter(val_dataset))\nprint(f\"Input:{context[idx].numpy().decode('utf-8')}\")\nprint(f\"Target:{target[idx].numpy().decode('utf-8')}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:59:20.274445Z","iopub.execute_input":"2025-12-19T16:59:20.274976Z","iopub.status.idle":"2025-12-19T16:59:20.317843Z","shell.execute_reply.started":"2025-12-19T16:59:20.274951Z","shell.execute_reply":"2025-12-19T16:59:20.317288Z"}},"outputs":[{"name":"stdout","text":"Input:Tom celebrated his twentieth birthday last week.\nTarget:Tom celebró su vigésimo cumpleaños la semana pasada.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def tf_lower_and_split_punct_w_special_tokens(text):\n  text = tf_text.normalize_utf8(text, 'NFKD')\n  text = tf.strings.lower(text)\n  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n  text = tf.strings.strip(text)\n\n  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n  return text\n\ndef tf_lower_and_split_punct(text):\n  text = tf_text.normalize_utf8(text, 'NFKD')\n  text = tf.strings.lower(text)\n  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n  text = tf.strings.strip(text)\n\n  return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:59:20.444575Z","iopub.execute_input":"2025-12-19T16:59:20.444849Z","iopub.status.idle":"2025-12-19T16:59:20.450012Z","shell.execute_reply.started":"2025-12-19T16:59:20.444830Z","shell.execute_reply":"2025-12-19T16:59:20.449306Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"print(target[idx].numpy().decode())\nprint(tf_lower_and_split_punct(target[idx]).numpy().decode())\nprint(tf_lower_and_split_punct_w_special_tokens(target[idx]).numpy().decode())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:59:22.391098Z","iopub.execute_input":"2025-12-19T16:59:22.391673Z","iopub.status.idle":"2025-12-19T16:59:22.408898Z","shell.execute_reply.started":"2025-12-19T16:59:22.391653Z","shell.execute_reply":"2025-12-19T16:59:22.408097Z"}},"outputs":[{"name":"stdout","text":"Tom celebró su vigésimo cumpleaños la semana pasada.\ntom celebro su vigesimo cumpleanos la semana pasada .\n[START] tom celebro su vigesimo cumpleanos la semana pasada . [END]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"with open('/kaggle/input/vocab/tensorflow2/default/1/context_vocab.pkl', 'rb') as f:\n    context_vocab = pickle.load(f)\n\nwith open('/kaggle/input/vocab/tensorflow2/default/1/target_vocab.pkl', 'rb') as f:\n    target_vocab = pickle.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:00:11.922941Z","iopub.execute_input":"2025-12-19T17:00:11.923664Z","iopub.status.idle":"2025-12-19T17:00:11.958639Z","shell.execute_reply.started":"2025-12-19T17:00:11.923640Z","shell.execute_reply":"2025-12-19T17:00:11.957916Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"context_text_processor = tf.keras.layers.TextVectorization(\n    standardize = tf_lower_and_split_punct,\n    max_tokens = config['max_vocab_size'],\n    output_sequence_length = config['max_length'],\n    vocabulary = context_vocab,\n    ragged = False)\n\ntarget_text_processor = tf.keras.layers.TextVectorization(\n    standardize = tf_lower_and_split_punct_w_special_tokens,\n    max_tokens = config['max_vocab_size'],\n    output_sequence_length = config['max_length'] + 1,\n    vocabulary = target_vocab,\n    ragged = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:00:13.789365Z","iopub.execute_input":"2025-12-19T17:00:13.789945Z","iopub.status.idle":"2025-12-19T17:00:13.879901Z","shell.execute_reply.started":"2025-12-19T17:00:13.789919Z","shell.execute_reply":"2025-12-19T17:00:13.879241Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# context_text_processor.adapt(train_dataset.map(lambda context, target: context))\n\nprint(context_text_processor.get_vocabulary()[:10])\n\n\n# target_text_processor.adapt(train_dataset.map(lambda context, target: target))\ntarget_text_processor.get_vocabulary()[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:00:19.869987Z","iopub.execute_input":"2025-12-19T17:00:19.870265Z","iopub.status.idle":"2025-12-19T17:00:19.896424Z","shell.execute_reply.started":"2025-12-19T17:00:19.870246Z","shell.execute_reply":"2025-12-19T17:00:19.895867Z"}},"outputs":[{"name":"stdout","text":"['', '[UNK]', '.', 'i', 'the', 'to', 'you', 'tom', '?', 'a']\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"['', '[UNK]', '[START]', '[END]', '.', 'que', 'el', 'de', 'no', 'tom']"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"def process_text(context, target):\n  context = context_text_processor(context)\n  target = target_text_processor(target)\n  targ_in = target[:,:-1]\n  targ_out = target[:,1:]\n  return (context, targ_in), targ_out\n\n\ntrain_dataset = train_dataset.map(process_text, num_parallel_calls=tf.data.AUTOTUNE)\nval_dataset = val_dataset.map(process_text, num_parallel_calls = tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:00:27.304400Z","iopub.execute_input":"2025-12-19T17:00:27.304694Z","iopub.status.idle":"2025-12-19T17:00:27.481827Z","shell.execute_reply.started":"2025-12-19T17:00:27.304675Z","shell.execute_reply":"2025-12-19T17:00:27.481261Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"for (ex_context_tok, ex_tar_in), ex_tar_out in val_dataset.take(1):\n  print(ex_context_tok[0, :10].numpy()) \n  print(ex_context_tok.shape)\n  print(ex_tar_in[0, :10].numpy()) \n  print(ex_tar_out[0, :10].numpy())\n  print(ex_tar_out.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:00:27.482864Z","iopub.execute_input":"2025-12-19T17:00:27.483148Z","iopub.status.idle":"2025-12-19T17:00:27.563591Z","shell.execute_reply.started":"2025-12-19T17:00:27.483125Z","shell.execute_reply":"2025-12-19T17:00:27.562988Z"}},"outputs":[{"name":"stdout","text":"[  18   10    4  297 4408   19    3  212  179    2]\n(512, 50)\n[   2   42 4238   14 1118   36    5  592  137    4]\n[  42 4238   14 1118   36    5  592  137    4    3]\n(512, 50)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"def Build_Seq2Seq(max_length=157, vocab_size_en=10000, vocab_size_es=10000, embedding_dim=256, units=512):\n    encoder_input = tf.keras.layers.Input(shape=(max_length,), dtype=\"int32\", name='encoder_input')\n    \n    enc_emb = tf.keras.layers.Embedding(vocab_size_en, embedding_dim, mask_zero=True)(encoder_input)\n    enc_emb = tf.keras.layers.Dropout(0.2)(enc_emb)\n    \n    encoder = tf.keras.layers.Bidirectional(\n        tf.keras.layers.LSTM(\n            units, \n            return_sequences=True, \n            return_state=True,\n            name='encoder_lstm'\n        )\n    )\n    \n    encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(enc_emb)\n    \n    encoder_state_h = tf.keras.layers.Concatenate(axis=-1)([forward_h, backward_h])\n    encoder_state_c = tf.keras.layers.Concatenate(axis=-1)([forward_c, backward_c])\n    \n    decoder_input = tf.keras.layers.Input(shape=(max_length,), dtype=\"int32\", name='decoder_input')\n    \n    dec_emb = tf.keras.layers.Embedding(vocab_size_es, embedding_dim, mask_zero=True)(decoder_input)\n    dec_emb = tf.keras.layers.Dropout(0.2)(dec_emb)\n    \n    decoder_outputs = tf.keras.layers.LSTM(\n        units * 2,\n        return_sequences=True,\n        return_state=False,\n        name='decoder_lstm'\n    )(dec_emb, initial_state=[encoder_state_h, encoder_state_c])\n    \n   \n    attention_output = tf.keras.layers.MultiHeadAttention(\n        num_heads=8,\n        key_dim=units * 2, \n        name='cross_attention'\n    )(\n        query=decoder_outputs, \n        value=encoder_outputs,  \n        key=encoder_outputs     \n    )\n    \n    decoder_combined = tf.keras.layers.Concatenate(axis=-1)([decoder_outputs, attention_output])\n    \n    outputs = tf.keras.layers.Dense(vocab_size_es, activation='softmax', name='output_dense')(decoder_combined)\n    \n    model = tf.keras.Model(inputs=[encoder_input, decoder_input], outputs=outputs, name='seq2seq')\n    return model\nvocab_size_en = context_text_processor.vocabulary_size()\nvocab_size_fr = target_text_processor.vocabulary_size()\nprint(f\"English vocab size: {vocab_size_en}\")\nprint(f\"French vocab size: {vocab_size_fr}\")\n\nwith strategy.scope():\n    model = Build_Seq2Seq(\n        max_length=config['max_length'], \n        vocab_size_en=vocab_size_en,\n        vocab_size_es=vocab_size_fr,\n        embedding_dim=256,\n        units=256  \n      \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:01:53.088681Z","iopub.execute_input":"2025-12-19T17:01:53.089384Z","iopub.status.idle":"2025-12-19T17:01:55.634159Z","shell.execute_reply.started":"2025-12-19T17:01:53.089360Z","shell.execute_reply":"2025-12-19T17:01:55.633350Z"}},"outputs":[{"name":"stdout","text":"English vocab size: 5000\nFrench vocab size: 5000\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:01:55.635484Z","iopub.execute_input":"2025-12-19T17:01:55.635776Z","iopub.status.idle":"2025-12-19T17:01:55.670573Z","shell.execute_reply.started":"2025-12-19T17:01:55.635752Z","shell.execute_reply":"2025-12-19T17:01:55.670078Z"}},"outputs":[{"name":"stdout","text":"Model: \"seq2seq\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n encoder_input (InputLayer)  [(None, 50)]                 0         []                            \n                                                                                                  \n embedding_4 (Embedding)     (None, 50, 256)              1280000   ['encoder_input[0][0]']       \n                                                                                                  \n decoder_input (InputLayer)  [(None, 50)]                 0         []                            \n                                                                                                  \n dropout_4 (Dropout)         (None, 50, 256)              0         ['embedding_4[0][0]']         \n                                                                                                  \n embedding_5 (Embedding)     (None, 50, 256)              1280000   ['decoder_input[0][0]']       \n                                                                                                  \n bidirectional_2 (Bidirecti  [(None, 50, 512),            1050624   ['dropout_4[0][0]']           \n onal)                        (None, 256),                                                        \n                              (None, 256),                                                        \n                              (None, 256),                                                        \n                              (None, 256)]                                                        \n                                                                                                  \n dropout_5 (Dropout)         (None, 50, 256)              0         ['embedding_5[0][0]']         \n                                                                                                  \n concatenate_6 (Concatenate  (None, 512)                  0         ['bidirectional_2[0][1]',     \n )                                                                   'bidirectional_2[0][3]']     \n                                                                                                  \n concatenate_7 (Concatenate  (None, 512)                  0         ['bidirectional_2[0][2]',     \n )                                                                   'bidirectional_2[0][4]']     \n                                                                                                  \n decoder_lstm (LSTM)         (None, 50, 512)              1574912   ['dropout_5[0][0]',           \n                                                                     'concatenate_6[0][0]',       \n                                                                     'concatenate_7[0][0]']       \n                                                                                                  \n cross_attention (MultiHead  (None, 50, 512)              8401408   ['decoder_lstm[0][0]',        \n Attention)                                                          'bidirectional_2[0][0]',     \n                                                                     'bidirectional_2[0][0]']     \n                                                                                                  \n concatenate_8 (Concatenate  (None, 50, 1024)             0         ['decoder_lstm[0][0]',        \n )                                                                   'cross_attention[0][0]']     \n                                                                                                  \n output_dense (Dense)        (None, 50, 5000)             5125000   ['concatenate_8[0][0]']       \n                                                                                                  \n==================================================================================================\nTotal params: 18711944 (71.38 MB)\nTrainable params: 18711944 (71.38 MB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"def masked_loss(y_true, y_pred):\n    \n    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n        from_logits=False,\n        reduction='none'\n    )\n    loss = loss_fn(y_true, y_pred) \n\n    mask = tf.cast(y_true != 0, loss.dtype)\n    loss *= mask\n\n    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n\n\ndef masked_acc(y_true, y_pred):\n    \n    y_pred = tf.argmax(y_pred, axis=-1)\n    y_pred = tf.cast(y_pred, y_true.dtype)\n\n    match = tf.cast(y_true == y_pred, tf.float32)\n    \n    mask = tf.cast(y_true != 0, tf.float32)\n\n    return tf.reduce_sum(match) / tf.reduce_sum(mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:01:57.650224Z","iopub.execute_input":"2025-12-19T17:01:57.650799Z","iopub.status.idle":"2025-12-19T17:01:57.655649Z","shell.execute_reply.started":"2025-12-19T17:01:57.650776Z","shell.execute_reply":"2025-12-19T17:01:57.654934Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"with strategy.scope():\n    model.compile(optimizer='adam',\n                  loss=masked_loss, \n                  metrics=[masked_acc])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:01:59.673760Z","iopub.execute_input":"2025-12-19T17:01:59.674473Z","iopub.status.idle":"2025-12-19T17:01:59.699158Z","shell.execute_reply.started":"2025-12-19T17:01:59.674447Z","shell.execute_reply":"2025-12-19T17:01:59.698591Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"history = model.fit(\n    train_dataset, \n    epochs=30,\n    validation_data=val_dataset,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=5,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.1,          \n            patience=3,           \n            min_lr=1e-7,          \n            verbose=1             \n        )\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:02:00.044125Z","iopub.execute_input":"2025-12-19T17:02:00.044339Z","iopub.status.idle":"2025-12-19T17:23:27.195513Z","shell.execute_reply.started":"2025-12-19T17:02:00.044323Z","shell.execute_reply":"2025-12-19T17:23:27.194805Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\nINFO:tensorflow:Collective all_reduce tensors: 19 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nINFO:tensorflow:Collective all_reduce IndexedSlices: 2 all_reduces, num_devices =2, group_size = 2, implementation = CommunicationImplementation.NCCL\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Collective all_reduce tensors: 19 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nINFO:tensorflow:Collective all_reduce IndexedSlices: 2 all_reduces, num_devices =2, group_size = 2, implementation = CommunicationImplementation.NCCL\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1766163741.123267     115 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1766163741.123282     113 cuda_dnn.cc:529] Loaded cuDNN version 90300\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1766163743.313329     113 service.cc:148] XLA service 0x7e1c92a1d690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1766163743.314329     113 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1766163743.314356     113 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1766163743.554911     115 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"209/209 [==============================] - ETA: 0s - loss: 4.6367 - masked_acc: 0.2823INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n209/209 [==============================] - 125s 485ms/step - loss: 4.6367 - masked_acc: 0.2823 - val_loss: 4.4665 - val_masked_acc: 0.2676 - lr: 0.0010\nEpoch 2/30\n209/209 [==============================] - 92s 437ms/step - loss: 2.8462 - masked_acc: 0.4952 - val_loss: 3.1098 - val_masked_acc: 0.4372 - lr: 0.0010\nEpoch 3/30\n209/209 [==============================] - 90s 431ms/step - loss: 1.8136 - masked_acc: 0.6432 - val_loss: 2.4368 - val_masked_acc: 0.5293 - lr: 0.0010\nEpoch 4/30\n209/209 [==============================] - 89s 426ms/step - loss: 1.3400 - masked_acc: 0.7142 - val_loss: 2.1041 - val_masked_acc: 0.5756 - lr: 0.0010\nEpoch 5/30\n209/209 [==============================] - 89s 425ms/step - loss: 1.1067 - masked_acc: 0.7500 - val_loss: 1.9595 - val_masked_acc: 0.5953 - lr: 0.0010\nEpoch 6/30\n209/209 [==============================] - 89s 424ms/step - loss: 0.9671 - masked_acc: 0.7727 - val_loss: 1.8933 - val_masked_acc: 0.6077 - lr: 0.0010\nEpoch 7/30\n209/209 [==============================] - 89s 426ms/step - loss: 0.8689 - masked_acc: 0.7891 - val_loss: 1.8480 - val_masked_acc: 0.6177 - lr: 0.0010\nEpoch 8/30\n209/209 [==============================] - 89s 423ms/step - loss: 0.7922 - masked_acc: 0.8020 - val_loss: 1.8615 - val_masked_acc: 0.6178 - lr: 0.0010\nEpoch 9/30\n209/209 [==============================] - 89s 426ms/step - loss: 0.7272 - masked_acc: 0.8144 - val_loss: 1.8364 - val_masked_acc: 0.6238 - lr: 0.0010\nEpoch 10/30\n209/209 [==============================] - 89s 424ms/step - loss: 0.6729 - masked_acc: 0.8242 - val_loss: 1.8626 - val_masked_acc: 0.6207 - lr: 0.0010\nEpoch 11/30\n209/209 [==============================] - 89s 424ms/step - loss: 0.6265 - masked_acc: 0.8337 - val_loss: 1.9040 - val_masked_acc: 0.6201 - lr: 0.0010\nEpoch 12/30\n209/209 [==============================] - ETA: 0s - loss: 0.5835 - masked_acc: 0.8425\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n209/209 [==============================] - 89s 424ms/step - loss: 0.5835 - masked_acc: 0.8425 - val_loss: 1.9151 - val_masked_acc: 0.6224 - lr: 0.0010\nEpoch 13/30\n209/209 [==============================] - 89s 424ms/step - loss: 0.4662 - masked_acc: 0.8718 - val_loss: 1.8763 - val_masked_acc: 0.6343 - lr: 1.0000e-04\nEpoch 14/30\n209/209 [==============================] - 89s 425ms/step - loss: 0.4382 - masked_acc: 0.8793 - val_loss: 1.9052 - val_masked_acc: 0.6330 - lr: 1.0000e-04\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"model.save(\"BI-LSTM-Cross-ATT.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:23:30.333080Z","iopub.execute_input":"2025-12-19T17:23:30.333927Z","iopub.status.idle":"2025-12-19T17:23:31.049279Z","shell.execute_reply.started":"2025-12-19T17:23:30.333865Z","shell.execute_reply":"2025-12-19T17:23:31.048621Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"model.save_weights(\"BI-LSTM-Cross-ATT.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:23:31.050445Z","iopub.execute_input":"2025-12-19T17:23:31.050665Z","iopub.status.idle":"2025-12-19T17:23:31.165958Z","shell.execute_reply.started":"2025-12-19T17:23:31.050648Z","shell.execute_reply":"2025-12-19T17:23:31.165350Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"loaded_model = tf.keras.models.load_model(\"/kaggle/working/BI-LSTM-Cross-ATT.keras\",compile=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:23:33.084313Z","iopub.execute_input":"2025-12-19T17:23:33.085051Z","iopub.status.idle":"2025-12-19T17:23:42.997266Z","shell.execute_reply.started":"2025-12-19T17:23:33.085025Z","shell.execute_reply":"2025-12-19T17:23:42.996601Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"(ex_context_tok, ex_tar_in), ex_tar_out = next(iter(val_dataset))\nprint(ex_context_tok.shape)\nprint(ex_tar_in[0, :10].numpy()) \nprint(ex_tar_out[0, :10].numpy())\nprint(ex_tar_out.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:23:42.998380Z","iopub.execute_input":"2025-12-19T17:23:42.998667Z","iopub.status.idle":"2025-12-19T17:23:43.050623Z","shell.execute_reply.started":"2025-12-19T17:23:42.998648Z","shell.execute_reply":"2025-12-19T17:23:43.049939Z"}},"outputs":[{"name":"stdout","text":"(512, 50)\n[   2   42 4238   14 1118   36    5  592  137    4]\n[  42 4238   14 1118   36    5  592  137    4    3]\n(512, 50)\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"def get_initial_state(model, context, target_text_processor):\n    if len(context.shape) == 1:\n        context = tf.expand_dims(context, 0)\n    \n    batch_size = tf.shape(context)[0]\n    vocab = target_text_processor.get_vocabulary()\n    start_token = vocab.index('[START]')\n    \n    next_token = tf.fill([batch_size, 1], start_token)\n    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n    \n    return next_token, done, context\n\n\ndef get_next_token(model, context, next_token, done, state, target_text_processor, temperature=0.0):\n    vocab = target_text_processor.get_vocabulary()\n    end_token = vocab.index('[END]')\n    \n    padded_state = tf.pad(state, [[0, 0], [0, config['max_length'] - tf.shape(state)[1]]])[:, :config['max_length']]\n    logits = model.predict([context, padded_state], verbose=0)\n    last_logits = logits[:, tf.shape(state)[1] - 1, :]\n    \n    if temperature == 0.0:\n        next_token_id = tf.argmax(last_logits, axis=-1, output_type=tf.int32)\n    else:\n        next_token_id = tf.squeeze(tf.random.categorical(last_logits / temperature, 1, dtype=tf.int32), -1)\n    \n    next_token_id = tf.expand_dims(next_token_id, -1)\n    done = done | (next_token_id == end_token)\n    next_token_id = tf.where(done, tf.constant(0, dtype=tf.int32), next_token_id)\n    new_state = tf.concat([state, next_token_id], axis=1)\n    \n    return next_token_id, done, new_state\n\n\ndef translate(model, spanish_text, target_text_processor, temperature=0.0):\n    if len(spanish_text.shape) == 1:\n        spanish_text = tf.expand_dims(spanish_text, 0)\n    \n    next_token, done, context = get_initial_state(model, spanish_text, target_text_processor)\n    state = next_token\n    tokens = []\n    \n    for n in range(config['max_length']):\n        next_token, done, state = get_next_token(model, context, next_token, done, state, target_text_processor, temperature)\n        tokens.append(next_token)\n        if tf.reduce_all(done):\n            break\n    \n    tokens = tf.concat(tokens, axis=-1)\n    vocab = target_text_processor.get_vocabulary()\n    \n    words = []\n    for token_id in tokens[0].numpy():\n        if token_id == 0:\n            break\n        word = vocab[token_id]\n        if word == '[END]':\n            break\n        if word not in ['[START]', '[UNK]', '']:\n            words.append(word)\n    \n    return ' '.join(words)\n\n\ndef compare_translations(model, spanish_input, target_out, context_text_processor, target_text_processor, n=5):\n    spanish_vocab = context_text_processor.get_vocabulary()\n    english_vocab = target_text_processor.get_vocabulary()\n    \n    for i in range(min(n, spanish_input.shape[0])):\n        # Spanish input\n        sp_words = [spanish_vocab[t] for t in spanish_input[i].numpy() if t > 0]\n        spanish = ' '.join(sp_words)\n        \n        # Ground truth English\n        gt_words = [english_vocab[t] for t in target_out[i].numpy() \n                    if t > 0 and english_vocab[t] not in ['[START]', '[END]']]\n        ground_truth = ' '.join(gt_words)\n        \n        # Model translation\n        model_output = translate(model, spanish_input[i], target_text_processor)\n        \n        print(f\"\\n{i+1}. English: {spanish}\")\n        print(f\"   GROUNDTRUTH: {ground_truth}\")\n        print(f\"   TRANSLATION: {model_output}\")\n\n\nval_iter = iter(val_dataset)\n\n(ex_context_tok, ex_tar_in), ex_tar_out = next(val_iter)\ncompare_translations(loaded_model, ex_context_tok, ex_tar_out, context_text_processor, target_text_processor, n=5)\n\n(ex_context_tok, ex_tar_in), ex_tar_out = next(val_iter)\ncompare_translations(loaded_model, ex_context_tok, ex_tar_out, context_text_processor, target_text_processor, n=5)\n\n(ex_context_tok, ex_tar_in), ex_tar_out = next(val_iter)\ncompare_translations(loaded_model, ex_context_tok, ex_tar_out, context_text_processor, target_text_processor, n=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T17:24:03.786144Z","iopub.execute_input":"2025-12-19T17:24:03.786671Z","iopub.status.idle":"2025-12-19T17:24:19.333835Z","shell.execute_reply.started":"2025-12-19T17:24:03.786648Z","shell.execute_reply":"2025-12-19T17:24:19.333129Z"}},"outputs":[{"name":"stdout","text":"\n1. English: this is the same necklace that i lost yesterday .\n   GROUNDTRUTH: este collar es igual al que perdi ayer .\n   TRANSLATION: este es el mismo jugador que perdi ayer .\n\n2. English: this is the strongest dog that i have ever seen .\n   GROUNDTRUTH: este es el perro mas fuerte que jamas haya visto .\n   TRANSLATION: este es el perro mas fuerte que haya visto nunca .\n\n3. English: this is your last chance to spend time with tom .\n   GROUNDTRUTH: esta es tu ultima oportunidad de pasar tiempo con tom .\n   TRANSLATION: esta es tu ultima oportunidad de pasar tiempo con tom .\n\n4. English: this material will stand up to lots of [UNK] .\n   GROUNDTRUTH: este material [UNK] un monton de [UNK] .\n   TRANSLATION: este se a muchas .\n\n5. English: this medicine should be taken every three hours .\n   GROUNDTRUTH: este medicamento debe ser tomado cada tres horas .\n   TRANSLATION: este remedio deberia cada tres horas .\n\n1. English: his salary is double what it was seven years ago .\n   GROUNDTRUTH: su sueldo es el doble del de hace siete anos atras .\n   TRANSLATION: su salario es doble que es siete anos .\n\n2. English: how come you know so much about japanese history ?\n   GROUNDTRUTH: ¿ como es que sabes tanto sobre la historia de japon ?\n   TRANSLATION: ¿ como sabes tanto de japon acerca de historia ?\n\n3. English: how many christmas cards did you write last year ?\n   GROUNDTRUTH: ¿ cuantos [UNK] [UNK] el ano pasado ?\n   TRANSLATION: ¿ cuantas tarjetas de navidad pusiste el ano pasado ?\n\n4. English: how many books do you think you have read so far ?\n   GROUNDTRUTH: ¿ cuantos libros crees que has leido hasta ahora ?\n   TRANSLATION: ¿ cuantos libros crees que has leido hasta ahora ?\n\n5. English: how many hours a day do you spend in your office ?\n   GROUNDTRUTH: ¿ cuantas horas al dia pasas en tu oficina ?\n   TRANSLATION: ¿ cuantas horas en tu oficina ?\n\n1. English: the soldiers were ready to die for their country .\n   GROUNDTRUTH: los soldados estaban [UNK] a morir por su pais .\n   TRANSLATION: los soldados estaban listos para morir su pais .\n\n2. English: the storm prevented me from going out for a walk .\n   GROUNDTRUTH: la tormenta me impidio el salir a dar un paseo .\n   TRANSLATION: la tormenta me impidio salir a dar un paseo .\n\n3. English: the [UNK] becomes [UNK] as you move [UNK] .\n   GROUNDTRUTH: la [UNK] es menos profundo a medida que [UNK] por el .\n   TRANSLATION: el se vuelve a como .\n\n4. English: the strong wind [UNK] that a storm is coming .\n   GROUNDTRUTH: el fuerte viento [UNK] que se acerca una tormenta .\n   TRANSLATION: el viento se a que viene .\n\n5. English: the students are happy , but the teachers are not .\n   GROUNDTRUTH: los estudiantes son felices , pero los profesores no lo son .\n   TRANSLATION: los estudiantes estan felices , pero el profesores no son .\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}